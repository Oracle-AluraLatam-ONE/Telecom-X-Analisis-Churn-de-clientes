# -*- coding: utf-8 -*-
"""TelecomX_LATAM.ipynb

Automatically generated by Colab.

Original file is located at
    https://colab.research.google.com/drive/1TwkJj40_KTe5aOXhZMD2Qb12QzK6Quyn

#üìå 1. Extracci√≥n

##Importamos libreria
* cargamos el ds
"""

import pandas as pd
import numpy as np
import matplotlib.pyplot as plt
import seaborn as sns
import requests
import json
from scipy import stats

# URL RAW del archivo JSON en GitHub
url = 'https://raw.githubusercontent.com/ingridcristh/challenge2-data-science-LATAM/main/TelecomX_Data.json'

# Descargar datos
response = requests.get(url)

# Verificar que la descarga fue exitosa
# Verificar que la descarga fue exitosa
if response.status_code == 200:
    data = json.loads(response.text)

    # Vista previa b√°sica
    print(type(data))        # debe ser una lista
    print('*******************')
    print(type(data[0]))     # debe ser un diccionario
    print('*******************')
    print(json.dumps(data[0], indent=2))  # ver primer registro
    print('*******************')
else:
    print("Error al descargar datos:", response.status_code)

"""## Se convierten los datos anidados en un DataFrame plano.
* Se verifica que los  datos est√°n organizados en jerarqu√≠as por lo que se usa json_normalize para aplanar su estructura anidada
"""

df= pd.json_normalize(data)
df.head()

"""Luego de aplanar la estructura anidada , verifico filas y columnas nuevamente

"""

print ('**************')
print('Filas y columnas :\n ', df.shape)

"""## Exploramos la estructura del dataset"""

# Ver informaci√≥n general del DataFrame
# Ver tipos de datos
print(df.dtypes)
print ('\n**************')

"""##  Verifico si hay valores nulos"""

print(df.isnull().sum().sum())

"""## Columnas
* Consulto las columnas para revisar las columnas m√°s relevantes para el an√°lisis  de evasion de clientes. (Churn)
"""

print('Columnas')
for col in df.columns:
  print ('-', col)

# Eliminar espacios por si acaso
df.columns = df.columns.str.strip()

# Mostrar los valores √∫nicos en la columna Churn
print(f"Valores √∫nicos en la columna Churn:\n")
print(df['Churn'].unique())
print('\n*****************************')

# Mostrar el conteo, incluyendo posibles vac√≠os
churn_counts = df['Churn'].value_counts(dropna=False)
print('\nConteo de valores en Churn (incluye vac√≠os):')
print(churn_counts)

# Verificar si hay valores vac√≠os ('') espec√≠ficamente
if (df['Churn'] == '').any():
    print('\n‚ö†Ô∏è  Atenci√≥n: Hay valores vac√≠os ("") en la columna Churn.')

"""##  Se verifican 224 datos de Churn vacios,  
* debo evaluar esto desde dos √°ngulos: tama√±o de la p√©rdida de datos y sentido anal√≠tico.
* Los valores vacios no pueden analizarse
* Evalua cual es el porcentaje de churn vacios para saber si el menos de 5%



"""

# Filtrar registros con valor vac√≠o en 'Churn'
faltantes = df[df['Churn'] == '']
print("Registros con 'Churn' vac√≠o:", len(faltantes))
# Verificar si hay registros con 'Churn' vac√≠o

print ('*****************************')

print( f" \nChurn Nulos {df ['Churn'].isna().mean()*100:.2f}%")
print (f"\n Churn Vac√≠os  {(df ['Churn'] == '').mean()*100:.2f}%")

"""##   Se eliminan los churn vacios"""

# Eliminar filas donde Churn es una cadena vac√≠a
df = df[df['Churn'] != '']

# Verificar que se eliminaron correctamente
print(f"Valores √∫nicos en Churn despu√©s de limpiar: {df['Churn'].unique()}")
# Mostrar el conteo, incluyendo posibles vac√≠os
churn_counts = df['Churn'].value_counts(dropna=False)
print('\nConteo de valores en Churn sin filas vac√≠as:')
print(churn_counts)

"""##  Verificar duplicados"""

duplicados = df.duplicated().sum()
print(f"\nFilas duplicadas en el dataset: {duplicados}")

"""#üîß 2.Transformaci√≥n

### Explorar columnas y tipos de datos
"""

print("\nTipos de datos por columna:")
print(df.dtypes)
df.info()

"""## Renombrar columnas anidadas para mayor claridad."""

print(df.columns.tolist())

"""### Renombrar columnas eliminando el prefijo (lo que est√° antes del '.')"""

## 2.1 Renombrado de columnas
# Eliminar prefijos como 'customer.', 'phone.', etc.
df.columns = df.columns.str.replace('customer.', '', regex=False)\
                       .str.replace('phone.', '', regex=False)\
                       .str.replace('internet.', '', regex=False)\
                       .str.replace('account.', '', regex=False)
print(f"Columnas renombradas:\n", df.columns.tolist())

"""##  Crear diccionario de datos a partir del archivo Markdown

"""

import requests

# URL RAW del diccionario en GitHub
url = 'https://raw.githubusercontent.com/Oracle-AluraLatam-ONE/Telecom-X-Analisis-Churn-de-clientes/main/file/TelecomX_diccionario.md'

# Descargar el archivo
response = requests.get(url)
texto_diccionario = response.text

# Convertir a diccionario Python limpiando Markdown
diccionario_columnas = {}

for linea in texto_diccionario.split('\n'):
    if ':' in linea:
        columna, descripcion = linea.split(':', 1)
        # Limpiar caracteres Markdown: guiones, backticks, espacios extra
        columna = columna.replace('-', '').replace('`', '').strip()
        diccionario_columnas[columna] = descripcion.strip()

# ‚úÖ Ejemplo de b√∫squeda
print("Significado de 'SeniorCitizen':", diccionario_columnas.get('SeniorCitizen', 'Descripci√≥n no encontrada'))

# ‚úÖ Ver claves disponibles
print("\nColumnas disponibles en el diccionario:")
print(list(diccionario_columnas.keys()))

"""## Transformar datos: conversiones de tipo
Algunas columnas que parecen num√©ricas en realidad vienen como texto (por ejemplo, "Charges.Total"), lo cual puede causar errores en an√°lisis y gr√°ficos.

"""

print (df[['tenure', 'Charges.Monthly',	'Charges.Total']].dtypes)

# Convertir TotalCharges a num√©rico
df['Charges.Total'] = pd.to_numeric(df['Charges.Total'], errors='coerce')
print (df[['tenure', 'Charges.Monthly',	'Charges.Total']].dtypes)

"""# Crear columna Cuentas_Diarias
 Usamos Charges.Monthly dividido entre 30 para obtener el promedio diario

 ###  Creaci√≥n de Cuentas_Diarias
A partir de la facturaci√≥n mensual (`Charges.Monthly`), se gener√≥ la columna `Cuentas_Diarias` calculando el valor diario promedio.  
Este indicador permite analizar patrones de gasto de forma m√°s granular a lo largo del tiempo.

"""

df['Cuentas_Diarias'] = df['Charges.Monthly'] / 30

# Confirmamos creaci√≥n
print(df[['Charges.Monthly', 'Cuentas_Diarias']].head())

# Validamos que no existan valores nulos cr√≠ticos
print("\nValores nulos en Cuentas_Diarias:", df['Cuentas_Diarias'].isna().sum())

"""## Comenzar la codificaci√≥n de categor√≠as.

Antes de crear modelos o hacer comparaciones num√©ricas, es √∫til codificar columnas:
- Para variables binarias (Yes/No) usamos 1/0.
- Para variables multicategor√≠a (Contract, InternetService, PaymentMethod) usamos *one-hot* (columnas dummy).
No es obligatorio para an√°lisis descriptivo, pero facilita c√°lculo de proporciones y gr√°ficas.

"""

# 2.4 Preparar: revisar nombres de columnas actuales y tipos
print("Columnas actuales:")
print(df.columns.tolist())
print("\nTipos de datos (resumen):")
print(df.dtypes.value_counts())

"""##Mapear binarias (Yes/No) -> 1/0

"""

binarias = ['Partner','Dependents','PhoneService','PaperlessBilling','Churn']  # 'Churn' es objetivo
# Asegurarse que las columnas est√©n en el df antes de mapear
bin_exist = [c for c in binarias if c in df.columns]

for col in bin_exist:
    df[col] = df[col].replace({'Yes':1,'No':0,'yes':1,'no':0})
    # Si qued√≥ alg√∫n valor extra√±o, intentamos forzar numeric
    df[col] = pd.to_numeric(df[col], errors='coerce').astype('Int64')

print("Columnas binarias mapeadas:", bin_exist)
display(df[bin_exist].head())

"""###  One-hot encoding para columnas multicategor√≠a
 Buscar columnas candidatas (contrato, internet, payment)
"""

cands = [c for c in ['Contract','InternetService','PaymentMethod','gender'] if c in df.columns]
cands

"""### Churn vs Categ√≥ricas (reparar uso de columnas originales) hay que conservar las columnas originales antes de codificar para este an√°lisis."""

# Guardar copia de columnas categ√≥ricas originales para an√°lisis posteriores
df_categoricas_original = df[['Contract', 'InternetService', 'PaymentMethod', 'gender', 'SeniorCitizen']].copy()

# Realizar get_dummies para estas columnas (si existen)
cols_onehot = [c for c in cands if c in df.columns]
print("One-hot para:", cols_onehot)
df = pd.get_dummies(df, columns=cols_onehot, prefix=cols_onehot, drop_first=False)
print("One-hot creadas. Columnas actuales (ejemplo principio):")
print(df.columns.tolist()[:40])

"""##  Consultar y comentar las columnas usando el diccionario
Vamos a crear una tabla resumen con: columna | tipo | significado (si est√° en el diccionario).

"""

if 'diccionario_columnas' not in globals():
    url_dic = 'https://raw.githubusercontent.com/Oracle-AluraLatam-ONE/Telecom-X-Analisis-Churn-de-clientes/main/file/TelecomX_diccionario.md'
    try:
        txt = requests.get(url_dic, timeout=10).text
        diccionario_columnas = {}
        for linea in txt.splitlines():
            if ':' in linea:
                k, v = linea.split(':', 1)
                k = k.replace('-', '').replace('`', '').strip()
                diccionario_columnas[k] = v.strip()
    except Exception as e:
        diccionario_columnas = {}
        print("No se pudo cargar diccionario:", e)

# Normalizar claves a min√∫sculas para buscar coincidencias
dic_lower = {k.lower(): v for k,v in diccionario_columnas.items()}

# Construir resumen
resumen = []
for col in df.columns:
    key = col.lower()
    # intentar varios matches comunes
    desc = dic_lower.get(key)
    if desc is None:
        # intentar con puntos removidos
        desc = dic_lower.get(key.replace('_','').replace(' ',''))
    if desc is None and '.' in key:
        desc = dic_lower.get(key.split('.')[-1])
    resumen.append({'columna': col, 'dtype': str(df[col].dtype), 'descripcion': desc or 'Descripci√≥n no disponible'})

resumen_df = pd.DataFrame(resumen)
display(resumen_df)

"""#> Revisa la tabla: para cada columna ten√©s el tipo y la descripci√≥n si est√° en el diccionario.  
> Si alguna descripci√≥n falta, pod√©s copiarla manualmente desde `TelecomX_diccionario.md`.

##  Reemplazar valores no est√°ndar
Algunos campos usan textos como `"No internet service"` o `"No phone service"`. Para an√°lisis conviene estandarizarlos (ej. 'No').
"""

# 2.6 Reemplazar textos especiales por 'No' en columnas que suelen tener esos valores
reemplazos = {'No internet service':'No', 'No phone service':'No', 'No internet': 'No'}
obj_cols = df.select_dtypes(include=['object']).columns.tolist()
for c in obj_cols:
    # aplicar solo si contiene esos valores
    if df[c].isin(reemplazos.keys()).any():
        df[c] = df[c].replace(reemplazos)
        print("Reemplazado en:", c)

# Confirmaci√≥n r√°pida (ver si qued√≥ algo con 'No internet')
for c in obj_cols:
    if df[c].astype(str).str.contains('No internet', na=False).any():
        print("Atenci√≥n, sigue 'No internet' en:", c)

"""##  Detectar outliers en `Charges.Monthly` (MonthlyCharges) y `tenure`
Usaremos IQR para ver valores extremos y, si corresponde, reportarlos. No eliminamos autom√°ticamente ‚Äî solo detectamos.

"""

# 2.7 Identificar nombres de columnas num√©ricas relevantes
num_candidates = []
for name in df.columns:
    ln = name.lower()
    if 'monthly' in ln or 'charges.monthly' in ln or 'charges_monthly' in ln or 'monthlycharges' in ln:
        num_candidates.append(name)
    if 'total' in ln and 'charge' in ln:
        num_candidates.append(name)
    if 'tenure' == ln:
        num_candidates.append(name)
# Dejamos √∫nicos
num_candidates = list(dict.fromkeys(num_candidates))
print("Candidatas num√©ricas identificadas:", num_candidates)

# Seleccionar Tenure, Monthly y Total si existen
ten_col = 'tenure' if 'tenure' in df.columns else None
monthly_col = None
total_col = None
for c in df.columns:
    if 'monthly' in c.lower() and monthly_col is None:
        monthly_col = c
    if 'total' in c.lower() and total_col is None:
        total_col = c

print("tenure:", ten_col, "monthly:", monthly_col, "total:", total_col)

# Funci√≥n IQR outliers
def iqr_outliers(series):
    q1 = series.quantile(0.25)
    q3 = series.quantile(0.75)
    iqr = q3 - q1
    low = q1 - 1.5*iqr
    high = q3 + 1.5*iqr
    out = series[(series < low) | (series > high)]
    return {'count': out.count(), 'low': low, 'high': high, 'outliers_sample': out.head().tolist()}

for col in [ten_col, monthly_col, total_col]:
    if col and col in df.columns and pd.api.types.is_numeric_dtype(df[col]):
        res = iqr_outliers(df[col].dropna())
        print(f"\nOutliers en {col}: {res['count']} (low_threshold={res['low']:.2f}, high_threshold={res['high']:.2f})")
        print("Ejemplo outliers (muestra):", res['outliers_sample'])

"""> Si hay outliers en `Monthly` o `Total`, no es obligatorio eliminarlos: revis√° si son valores v√°lidos (clientes con muchos meses y cargos altos). Si son errores (por ej. 99999), conviene corregirlos o eliminarlos. Documentalo en el informe.

#üìä 3.Carga y an√°lisis de dataset limpio (opcional pero recomendado)
Guardamos una copia CSV del dataset ya transformado.

##   Dejar una copia del dataset limpio (por ejemplo, guardar en .csv).
"""

# Guardar CSV
df.to_csv('TelecomX_limpio_transformado.csv', index=False)
print("Guardado: TelecomX_limpio_transformado.csv")

"""##  Confirmar que el dataset transformado est√° listo (sin nulos cr√≠ticos)
Comprobamos nulos y tipos finales.

## Confirmar que el dataset transformado est√° listo (sin nulos cr√≠ticos)
Comprobamos nulos y tipos finales.
"""

# 3.2 Revisi√≥n final: nulos por columna y tipos
display(pd.DataFrame({'dtype': df.dtypes, 'nulos': df.isna().sum(), 'nulos_pct': (df.isna().mean()*100).round(2)}))

"""## An√°lisis descriptivo general

Se calculan medidas estad√≠sticas para todas las variables del dataset:
- **Num√©ricas**: promedio, mediana, desviaci√≥n est√°ndar, valores m√≠nimo y m√°ximo.
- **Categ√≥ricas**: cantidad de categor√≠as √∫nicas y valores m√°s frecuentes.

**Principales observaciones:**
- `tenure` promedio de ~32 meses, m√≠nimo de 0 y m√°ximo de 72.
- `Charges.Monthly` promedio de ~64 USD, con un rango amplio que refleja diferentes combinaciones de servicios.
- `Charges.Total` var√≠a desde valores muy bajos (clientes nuevos) hasta m√°s de 8.000 USD (clientes de larga permanencia).
- `Cuentas_Diarias` promedio de ~2,1 USD/d√≠a.

"""

# An√°lisis descriptivo general
desc_stats = df.describe(include='all').transpose()

# Mostramos las estad√≠sticas
display(desc_stats)

# Comentarios autom√°ticos b√°sicos
print("Cantidad de registros:", df.shape[0])
print("Cantidad de columnas:", df.shape[1])
print("\nVariables num√©ricas analizadas: tenure, Charges.Monthly, Charges.Total, Cuentas_Diarias")

"""## (Opcional) Separaci√≥n train/test ‚Äî solo si vas a modelar despu√©s
Mostramos c√≥mo hacerlo en caso de que lo necesites (no obligatorio para la TAREA).

"""

from sklearn.model_selection import train_test_split

if 'Churn' in df.columns:
    # Si Churn est√° codificado 1/0 conviene usarlo; si no, mapear primero
    if df['Churn'].dtype.name in ['object','category']:
        # mapear temporalmente para separar
        df['Churn_tmp'] = df['Churn'].replace({'Yes':1,'No':0})
    else:
        df['Churn_tmp'] = df['Churn']
    X = df.drop(columns=['Churn','Churn_tmp']) if 'Churn' in df.columns else df.copy()
    y = df['Churn_tmp']
    X_train, X_test, y_train, y_test = train_test_split(X, y, stratify=y, test_size=0.2, random_state=42)
    print("Split realizado. Train:", X_train.shape, "Test:", X_test.shape)
    # eliminar columna temporal si no la quer√©s mantener
    df.drop(columns=['Churn_tmp'], inplace=True, errors=False)
else:
    print("No hay columna Churn para split.")

"""## Distribuci√≥n de Churn (conteo y porcentaje)

"""

# 3.4 Si Churn est√° codificada como 0/1 o 'Yes'/'No' detectamos ambas posibilidades
if 'Churn' in df.columns:
    # Si est√° en 1/0: convertir a etiquetas para mostrar
    if pd.api.types.is_integer_dtype(df['Churn']) or pd.api.types.is_float_dtype(df['Churn']):
        df['Churn_label'] = df['Churn'].map({0:'No', 1:'Yes'})
    else:
        df['Churn_label'] = df['Churn'].astype(str)
    counts = df['Churn_label'].value_counts()
    pct = (df['Churn_label'].value_counts(normalize=True)*100).round(2)
    churn_sum = pd.DataFrame({'count': counts, 'percent': pct})
    display(churn_sum)
    plt.figure(figsize=(5,4))
    sns.countplot(x='Churn_label', data=df)
    plt.title('Distribuci√≥n de Churn')
    plt.show()
else:
    print("Columna Churn no encontrada.")

"""##Churn vs Variables Categ√≥ricas
Se analiz√≥ la tasa de *churn* segmentada por:
- Tipo de contrato (`Contract`)
- Servicio de internet (`InternetService`)
- M√©todo de pago (`PaymentMethod`)
- G√©nero (`gender`)
- SeniorCitizen (indicador de edad ‚â• 65 a√±os)

**Hallazgos:**
- Contrato *Month-to-month* presenta la mayor tasa de churn (~43%).
- Clientes con *Fiber optic* tienen mayor churn que los de *DSL*.
- M√©todo de pago *Electronic check* presenta la tasa m√°s alta de churn.
- La variable `gender` no muestra diferencias significativas.
- Clientes mayores (SeniorCitizen=1) presentan mayor churn que los m√°s j√≥venes.

"""

# Usar las categ√≥ricas originales guardadas
for col in df_categoricas_original.columns:
    tab = pd.crosstab(df_categoricas_original[col], df['Churn_label'], normalize='index') * 100
    display(tab.round(2))
    tab.plot(kind='bar', stacked=True, figsize=(8,4))
    plt.title(f'Churn (%) por {col}')
    plt.ylabel('% por categor√≠a')
    plt.show()

"""##  Churn vs Num√©ricas: Tenure, MonthlyCharges, TotalCharges, Cuentas_Diarias
Usamos boxplots y distribuciones por churn.

"""

num_cols_plot = []
for c in ['tenure', monthly_col, total_col, 'Cuentas_Diarias']:
    if c and c in df.columns:
        if pd.api.types.is_numeric_dtype(df[c]):
            num_cols_plot.append(c)

print("Columnas num√©ricas a graficar:", num_cols_plot)
for c in num_cols_plot:
    plt.figure(figsize=(8,4))
    sns.boxplot(x='Churn_label', y=c, data=df)
    plt.title(f'{c} por Churn')
    plt.show()
    plt.figure(figsize=(8,4))
    sns.histplot(data=df, x=c, hue='Churn_label', bins=30, kde=True, element='step')
    plt.title(f'Distribuci√≥n de {c} por Churn')
    plt.show()

"""##  Correlaciones entre num√©ricas (incluye Churn codificado 0/1 si es num√©rico)

"""

# 3.7 Preparar matriz de correlaci√≥n con columnas num√©ricas clave
corr_cols = [c for c in [ten_col, monthly_col, total_col, 'Cuentas_Diarias'] if c in df.columns]
# A√±adir Churn si es num√©rico (mapear temporalmente)
if 'Churn_label' in df.columns:
    df['Churn_num'] = df['Churn_label'].map({'No':0,'Yes':1})
    corr_cols.append('Churn_num')

if len(corr_cols) >= 2:
    plt.figure(figsize=(6,4))
    sns.heatmap(df[corr_cols].corr(), annot=True, fmt=".2f", cmap='coolwarm')
    plt.title("Correlaci√≥n entre variables num√©ricas relevantes")
    plt.show()
# eliminar columna temporal si no la quer√©s mantener
df.drop(columns=['Churn_num'], inplace=True, errors=False)

"""#üìÑ4. Informe final
# An√°lisis de Evasi√≥n (Churn)

## Introducci√≥n
El presente an√°lisis tiene como objetivo identificar patrones y factores asociados a la evasi√≥n de clientes (*churn*) en la empresa **TelecomX**. La retenci√≥n de clientes es crucial para reducir costos y aumentar la rentabilidad, ya que adquirir nuevos clientes suele ser m√°s costoso que mantener a los actuales.

## Limpieza y Tratamiento de Datos
- Fuente de datos: archivo JSON obtenido desde la API de TelecomX.
- Normalizaci√≥n de estructura anidada con `pd.json_normalize`.
- Eliminaci√≥n de 224 registros con `Churn` vac√≠o (3,08% del total).
- Eliminaci√≥n de duplicados (0 encontrados).
- Conversi√≥n de `Charges.Total` a num√©rico; `Charges.Monthly` y `tenure` ya estaban en formato correcto.
- Creaci√≥n de `Cuentas_Diarias` = `Charges.Monthly` / 30.
- Estandarizaci√≥n de valores no uniformes ("No internet service" ‚Üí "No").
- Codificaci√≥n binaria para variables Yes/No y *one-hot encoding* para variables multicategor√≠a.

## An√°lisis Exploratorio de Datos

### Distribuci√≥n de Churn
La proporci√≥n de clientes que abandonaron el servicio es del **26,54%**, mientras que el 73,46% permanecen activos.
![Distribuci√≥n de Churn](attachment:dist_churn.png)

### Churn por Variables Categ√≥ricas
- **Contract**: `Month-to-month` presenta ~43% de churn, mientras que `Two year` baja a ~3%.
- **InternetService**: *Fiber optic* presenta mayor churn que *DSL* o *No service*.
- **PaymentMethod**: *Electronic check* lidera en churn, seguido por *Mailed check*.
- **SeniorCitizen**: tasa de churn m√°s alta en clientes mayores.

### Churn por Variables Num√©ricas
- **tenure**: los clientes con menor antig√ºedad son m√°s propensos a cancelar.
- **Charges.Monthly**: cargos mensuales m√°s altos se asocian con mayor churn en ciertos casos.
- **Charges.Total**: clientes con valores bajos suelen ser recientes y presentan m√°s churn.

### Correlaciones
La mayor correlaci√≥n positiva con `Churn` se observa en `Contract_Month-to-month` y la negativa en `tenure`.

---
## 4.1 Variable objetivo
La variable **objetivo** es `Churn` (1 = cliente que se dio de baja, 0 = cliente que permaneci√≥).  
Este campo ser√° la referencia para todos los an√°lisis posteriores.



## 4.2 Distribuci√≥n de Churn
La proporci√≥n de clientes que abandonaron el servicio es del **26,54%**, mientras que el **73,46%** permanecen activos.

---
## Conclusiones e Insights
1. Contratos mensuales representan un riesgo alto de fuga de clientes.
2. Clientes con internet de fibra √≥ptica requieren atenci√≥n especial para reducir cancelaciones.
3. El m√©todo de pago *Electronic check* podr√≠a estar vinculado a clientes menos fidelizados.
4. La antig√ºedad baja es un factor de riesgo importante.

## Recomendaciones
- **Fidelizaci√≥n**: Ofrecer descuentos o beneficios a clientes con contratos mensuales para incentivar contratos a largo plazo.
- **Servicio t√©cnico y valor percibido**: Mejorar la experiencia de clientes de fibra √≥ptica con soporte proactivo.
- **M√©todos de pago**: Incentivar pagos autom√°ticos o con tarjeta para clientes de alto riesgo.
- **Onboarding de nuevos clientes**: Implementar programas de bienvenida para los primeros 6 meses.

---
**Fin del informe**


"""

display(churn_sum)
sns.countplot(x='Churn_label', data=df)
plt.title('Distribuci√≥n de Churn')
plt.show()

"""##4.3 Variables explicativas clave
Tipo de contrato (Contract)
Month-to-month: ~43% de churn.

One year: ~11% de churn.

Two year: ~3% de churn.

Antig√ºedad (Tenure)
Clientes con < 12 meses de antig√ºedad muestran una tasa de churn muy superior.

Mayor permanencia ‚Üí menor probabilidad de churn.

Edad (SeniorCitizen)
SeniorCitizen = 1: ~42% churn.

SeniorCitizen = 0: ~24% churn.

M√©todo de pago (PaymentMethod)
Electronic check: mayor churn (~45%).

M√©todos autom√°ticos (tarjeta o d√©bito) ‚Üí menor churn.

Servicios contratados
Fiber optic: mayor churn (~41%) vs DSL (~19%).

Falta de servicios adicionales de seguridad o soporte correlaciona con mayor churn.



"""

# Categ√≥ricas
for col in df_categoricas_original.columns:
    tab = pd.crosstab(df_categoricas_original[col], df['Churn_label'], normalize='index') * 100
    display(tab.round(2))
    tab.plot(kind='bar', stacked=True, figsize=(8,4))
    plt.title(f'Churn (%) por {col}')
    plt.ylabel('% por categor√≠a')
    plt.show()

# Num√©ricas
for c in ['tenure', 'Charges.Monthly', 'Charges.Total', 'Cuentas_Diarias']:
    if c in df.columns:
        plt.figure(figsize=(8,4))
        sns.boxplot(x='Churn_label', y=c, data=df)
        plt.title(f'{c} por Churn')
        plt.show()

"""##Conclusiones preliminares y patrones detectados
Conclusiones e Insights
Contrato mensual es el factor m√°s asociado a churn (43% de bajas).

Menor antig√ºedad correlaciona fuertemente con abandono.

Clientes mayores presentan un riesgo mayor de cancelaci√≥n.

M√©todo de pago influye: Electronic check es menos estable.

Internet de fibra √≥ptica presenta mayor tasa de bajas que DSL.

Recomendaciones
Fidelizar contratos mensuales con descuentos o beneficios por permanencia.

Fortalecer onboarding para clientes nuevos (primeros 6 meses).

Campa√±as espec√≠ficas para mayores de 65 a√±os enfocadas en soporte y facilidad de uso.

Incentivar m√©todos de pago autom√°ticos.

Mejorar experiencia de clientes de fibra √≥ptica con soporte t√©cnico proactivo.


"""

df.to_csv("datos_tratados.csv", index=False)